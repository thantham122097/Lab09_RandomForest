{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21216943",
   "metadata": {},
   "source": [
    "# Programming for Data Science and Artificial Intelligence\n",
    "\n",
    "## Supervised Learning - Classification - Bagging and Random Forests\n",
    "\n",
    "## Name: Thantham Khamyai\n",
    "\n",
    "## Student ID: 122097"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230b665f",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "\n",
    "Modify the Bagging scratch code in our lecture such that:\n",
    "- Calculate for **oob** evaluation for each bootstrapped dataset, and also the average score\n",
    "- Change the code to **\"without replacement\"**\n",
    "- Put everything into a **class <code>Bagging</code>**.  It should have at least two methods, <code>fit(X_train, y_train)</code>, and <code>predict(X_test)</code>\n",
    "- Modify the code from above to randomize features.  Set the number of **features** to be used in each tree to be **<code>sqrt(n)</code>**, and then select a subset of features for each tree.  This can be easily done by setting our **DecisionTreeClassifier <code>max_features</code> to 'sqrt'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaa34706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d166a27",
   "metadata": {},
   "source": [
    "Load Iris Dataset into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9039e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                test_size=0.3, shuffle=True, random_state=48)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93656957",
   "metadata": {},
   "source": [
    "This section is to construct the Random Forest model. lets see the rounghly algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a01cdb",
   "metadata": {},
   "source": [
    "## Random Forest Algorithm\n",
    "\n",
    "### fit:\n",
    "1. define bootstap ratio, and n_tree\n",
    "2. Init booststrap samples and oob samples\n",
    "3. fill boostrap samples and oob samples\n",
    "4. use boostrap samples to make tree and check acc for oob\n",
    "\n",
    "### predict:\n",
    "1. fetch all test x to each tree\n",
    "2. get all predict and find majority\n",
    "\n",
    "### Task - Bagging class\n",
    "### Task - Max features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0305761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy import stats\n",
    "import random\n",
    "\n",
    "#class RandomForest:\n",
    "class Bagging:\n",
    "    \n",
    "    def __init__(self, n_estimators=10, bootstrap_ratio=0.8, no_replacement=True, # constructor===============\n",
    "                 max_features='sqrt', max_depth=None):\n",
    "        \n",
    "        self.B = n_estimators # same as number of decision tree in side models\n",
    "        self.bootstrap_ratio = bootstrap_ratio # fraction of sampling\n",
    "        self.no_replacement = no_replacement # not allow duplicate?\n",
    "        self.max_depth = max_depth # max depth of tree\n",
    "        self.max_features = max_features # mas feature allow in tree\n",
    "        self.tree_params = {'max_depth': self.max_depth, 'max_features': self.max_features} # make params for tree\n",
    "        self.trees = [DecisionTreeClassifier(**self.tree_params) for _ in range(self.B)] # init d.trees by B \n",
    "        \n",
    "        \n",
    "    def fit(self, X, y): # fit method =======================================================================\n",
    "        \n",
    "        m,n = X.shape # init m,n\n",
    "        self.num_class = len(np.unique(y)) # init number of unique output for make proba prediction\n",
    "        \n",
    "        # 1. define number of samples in boostrap out of all samples----------------------------------\n",
    "        n_sample_bootstrap = int(self.bootstrap_ratio * m)\n",
    "        \n",
    "        \n",
    "        # 2. init boostrap samples and oob smaples-----------------------------------------------------\n",
    "        x_bootstrap = np.zeros((self.B, n_sample_bootstrap, n)) # shape as (n_trees, n_samples, n_features)\n",
    "        y_bootstrap = np.zeros((self.B, n_sample_bootstrap)) # shape as (n_trees, n_samples)\n",
    "        \n",
    "        x_oob = [] # unknow shape \n",
    "        y_oob = [] # unknow shape\n",
    "        \n",
    "        \n",
    "        # 3. fill them bootstrap and oob---------------------------------------------------------------\n",
    "        \n",
    "        for tree_i in range(len(self.trees)): # for each tree\n",
    "            \n",
    "            sample_i = 0 # sample in bootstrap counter\n",
    "            \n",
    "            used_idx = [] # init replacement used idx\n",
    "            \n",
    "            bootstrap_idx = [] # init idx which are for bootstrap\n",
    "            \n",
    "            while sample_i < n_sample_bootstrap: # while sample in bootstrap is not more than defined n samples\n",
    "                \n",
    "                idx = random.randrange(0, m) # random bootstrap idx\n",
    "                \n",
    "                if self.no_replacement: # if not allow duplicate samples in bootstrap\n",
    "                    \n",
    "                    while idx in used_idx: # if randomed idx is duplicate with used\n",
    "                        \n",
    "                        idx = random.randrange(0, m) # newly random until found not duplicate\n",
    "                    \n",
    "                    used_idx.append(idx) # after found not duplicate idx save that idx for fuether random\n",
    "                \n",
    "                x_bootstrap[tree_i, sample_i, :] = X[idx, :] # append bootstrap X\n",
    "                y_bootstrap[tree_i, sample_i] = y[idx] # append bootstrap y\n",
    "                \n",
    "                bootstrap_idx.append(idx) # save this bootstrap idx\n",
    "                \n",
    "                sample_i += 1 # then -> find next sample to be bootstrao\n",
    "            \n",
    "             #after fullfill bootstrap, fetch idx which is not in bootstrap\n",
    "            oob_idx = list(set(np.arange(m)) - set(bootstrap_idx))\n",
    "            \n",
    "            # define oob samples\n",
    "            x_oob.append(X[oob_idx])\n",
    "            y_oob.append(y[oob_idx])\n",
    "        \n",
    "        # make it numpy ass because we will need it for indexing while validation\n",
    "        x_oob = np.asarray(x_oob, dtype='object')\n",
    "        y_oob = np.asarray(y_oob, dtype='object')\n",
    "        \n",
    "                \n",
    "        # 4. use boostrap samples making trees-------------------------------------------------------------\n",
    "        \n",
    "        self.oob_score_ = np.zeros((self.B)) # init list of oob score in each trees (n_trees,)\n",
    "        \n",
    "        for tree_i in range(self.B): # for each tree in model\n",
    "            \n",
    "            self.trees[tree_i].fit(x_bootstrap[tree_i], y_bootstrap[tree_i]) # fit x, y at bootstrap i\n",
    "            \n",
    "            y_pred_oob = self.trees[tree_i].predict(x_oob[tree_i]) # predict y_oob_pred at oob i\n",
    "            \n",
    "            self.oob_score_[tree_i] = sum(y_oob[tree_i]==y_pred_oob)/y_pred_oob.shape[0] # acc for current tree\n",
    "        \n",
    "        self.oob_avg_score_ = np.mean(self.oob_score_) # find everage oob score\n",
    "        \n",
    "\n",
    "    def predict(self, X): # predict method ==================================================================\n",
    "        \n",
    "        y_pred = np.zeros((self.B, X.shape[0])) # init prediction by (n_trees, n_output)\n",
    "        \n",
    "        for tree_i in range(self.B): # for each tree in model\n",
    "            y_pred[tree_i] = self.trees[tree_i].predict(X) # predict and keep in prediction of that tree\n",
    "        \n",
    "        return stats.mode(y_pred)[0][0] # return majority of predictions\n",
    "    \n",
    "    \n",
    "    def predict_proba(self, X): # predict by probability ====================================================\n",
    "        \n",
    "        y_pred = np.zeros((self.B, X.shape[0])) # init prediction by (n_trees, n_output)\n",
    "        \n",
    "        for tree_i in range(self.B): # for each tree in model\n",
    "            y_pred[tree_i] = self.trees[tree_i].predict(X) # predict and keep in prediction of that tree\n",
    "            \n",
    "        y_pred = y_pred.T.astype('int') # tranpose prediction (n_output, n_tree) -> (output i, result of tree i)\n",
    "        \n",
    "        y_prob = np.apply_along_axis(lambda x: np.bincount(x, minlength=self.num_class), \n",
    "                                     axis=1, arr=y_pred) # map bincount for each test sample\n",
    "        \n",
    "        return y_prob/self.B # return counted bin each sample with n_trees\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ac5f42",
   "metadata": {},
   "source": [
    "After constructing Bagging class (Random Forest), lets try model\n",
    "\n",
    "### Task - selective no_replacement option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6606b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Bagging(n_estimators=10, bootstrap_ratio = 0.8, no_replacement=False, max_features=None, max_depth=None)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c14889c",
   "metadata": {},
   "source": [
    "While fitting model, the oob scores were calculated. we can see by this\n",
    "\n",
    "### Task - OOB score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5527299c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== 10 trees ================\n",
      " Tree 1 has oob score: 0.9215686274509803\n",
      " Tree 2 has oob score: 1.0\n",
      " Tree 3 has oob score: 0.9811320754716981\n",
      " Tree 4 has oob score: 0.9545454545454546\n",
      " Tree 5 has oob score: 0.9347826086956522\n",
      " Tree 6 has oob score: 0.9148936170212766\n",
      " Tree 7 has oob score: 1.0\n",
      " Tree 8 has oob score: 0.9565217391304348\n",
      " Tree 9 has oob score: 0.9302325581395349\n",
      " Tree 10 has oob score: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "print(f'=========== {model.B} trees ================')\n",
    "for i in range(model.B):\n",
    "    print(f' Tree {i+1} has oob score: {model.oob_score_[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfed3f0",
   "metadata": {},
   "source": [
    "Moreover, we can print out averaged oob of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db159fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall average oob score: 0.9571454458232809\n"
     ]
    }
   ],
   "source": [
    "print(f'Overall average oob score: {model.oob_avg_score_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed5804a",
   "metadata": {},
   "source": [
    "Next, we can predict the output from testing set, and the output of predict method will be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "973d06e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 2. 0. 2. 2. 0. 2. 0. 1. 2. 0. 0. 2. 1. 1. 0. 1. 1. 2. 0. 2. 2. 1.\n",
      " 1. 0. 0. 2. 2. 1. 2. 1. 2. 0. 1. 2. 2. 1. 0. 1. 1. 1. 2. 2. 1.]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8469cf0",
   "metadata": {},
   "source": [
    "This is additional method, we can fuether predict by probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b6a7cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  1.  0. ]\n",
      " [0.  1.  0. ]\n",
      " [0.  0.3 0.7]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.4 0.6]\n",
      " [0.  0.  1. ]\n",
      " [1.  0.  0. ]\n",
      " [0.  0.4 0.6]\n",
      " [1.  0.  0. ]\n",
      " [0.  1.  0. ]]\n"
     ]
    }
   ],
   "source": [
    "y_prob = model.predict_proba(X_test)\n",
    "print(y_prob[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3d2678",
   "metadata": {},
   "source": [
    "Therefore, we try to examine classification report here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89b543e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.94      0.89      0.91        18\n",
      "           2       0.88      0.94      0.91        16\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ba13c",
   "metadata": {},
   "source": [
    "## Completed Tasks\n",
    "\n",
    "* Perform **OOB** score calculation\n",
    "* add option of **No replacement** bootstrap\n",
    "* make **Bagging class**\n",
    "* add option**max_feature** and set 'sqrt' by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afc95c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
